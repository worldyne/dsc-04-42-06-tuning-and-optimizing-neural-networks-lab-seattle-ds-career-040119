{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning and Optimizing Neural Networks - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Now that we've discussed some regularization, initialization and optimization techniques, its time to synthesize those concepts into a cohesive modelling pipeline.  \n",
    "\n",
    "With this pipeline, yoiu will not only fit an initial model but will also attempt to set various hyperparameters for regularization techniques. Your final model selection will pertain to the test metrics across these models. This will more naturally simulate a problem you might be faced with in practice, and the various modelling decisions you are apt to encounter along the way.  \n",
    "\n",
    "Recall that our end objective is to achieve a balance between overfitting and underfitting. We've discussed the bias variance tradeoff, and the role of regularization in order to reduce overfitting on training data and improving generalization to new cases. Common frameworks for such a procedure include train/validate/test methodology when data is plentiful, and K-folds cross-validation for smaller, more limited datasets. In this lab, you'll perform the latter, as the dataset in question is fairly limited. \n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Implement a K-folds cross validation modelling pipeline\n",
    "* Apply normalization as a preprocessing technique\n",
    "* Apply regularization techniques to improve your model's generalization\n",
    "* Choose an appropriate optimization strategy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; load and preview the dataset\n",
    "import pandas as pd\n",
    "df = pd.read_csv('loan_final.csv')\n",
    "df.head().T\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Problem\n",
    "\n",
    "Set up the problem by defining X and Y. \n",
    "\n",
    "For this problem use the following variables for X:\n",
    "* loan_amnt\n",
    "* home_ownership\n",
    "* funded_amnt_inv\n",
    "* verification_status\n",
    "* emp_length\n",
    "* installment\n",
    "* annual_inc\n",
    "\n",
    "Be sure to use dummy variables for categorical variables and to normalize numerical quanitities. Be sure to also remove any rows with null data.  \n",
    "\n",
    "For Y, we are looking to build a model to predict the total payment received for a loan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-0e038273f836>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0menc_vs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_vs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0menc_emp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_emp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mohe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_ho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0menc_ho\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mohe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_ho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mohe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'home_ownership'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mohe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_vs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, handle_unknown)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36m_check_X\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_get_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'assume_finite'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m_object_dtype_isnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input contains NaN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN"
     ]
    }
   ],
   "source": [
    "# Your code here; appropriately define X and Y using dummy variables and normalization for preprocessing.\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "X = df[['loan_amnt', 'home_ownership', 'funded_amnt_inv', 'verification_status',\n",
    "       'emp_length', 'installment', 'annual_inc']]\n",
    "ohe = OneHotEncoder()\n",
    "ss = StandardScaler()\n",
    "\n",
    "enc_ho = X['home_ownership']\n",
    "enc_vs = X['verification_status']\n",
    "enc_emp = X['emp_length']\n",
    "enc_ho = enc_ho.values.reshape(-1,1)\n",
    "enc_vs = enc_vs.values.reshape(-1,1)\n",
    "enc_emp = enc_emp.values.reshape(-1, 1)\n",
    "ohe.fit(enc_ho)\n",
    "enc_ho = pd.DataFrame(ohe.transform(enc_ho).toarray(), columns=ohe.get_feature_names(['home_ownership']))\n",
    "ohe.fit(enc_vs)\n",
    "enc_vs = pd.DataFrame(ohe.transform(enc_vs).toarray(), columns=ohe.get_feature_names(['verification_status']))\n",
    "ohe.fit(enc_emp)\n",
    "enc_emp = pd.DataFrame(ohe.transform(enc_emp).toarray(), columns=ohe.get_feature_names(['emp_length']))\n",
    "\n",
    "X_s = X.drop(['home_ownership', 'verification_status', 'emp_length'],axis=1)\n",
    "X_s = pd.DataFrame(ss.fit_transform(X_s), columns=X_s.columns)\n",
    "\n",
    "X = pd.concat([X_s, enc_ho, enc_vs], axis=1)\n",
    "\n",
    "y = df['total_pymnt']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a Hold Out Test Set\n",
    "\n",
    "While we will be using K-fold cross validation to select an optimal model, we still want a final hold out test set that is completely independent of any modelling decisions. As such, pull out a sample of 10% of the total available data. For consistency of results, use random seed 123. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here; generate a hold out test set for final model evaluation. Use random seed 123.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.1, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a K-fold Cross Validation Methodology\n",
    "\n",
    "Now that your have a complete holdout test set, write a function that takes in the remaining data and performs k-folds cross validation given a model object. Be sure your function returns performance metrics regarding the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; define a function to evaluate a model object using K folds cross validation.\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def k_folds(features_train, labels_train, model_obj, k=10, n_epochs=100):\n",
    "    colors = sns.color_palette(\"Set2\")\n",
    "    kf = KFold(n_splits=10,shuffle=True)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 5, figsize=(12,8))\n",
    "    validation_scores = []\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(features_train)):\n",
    "        row = i//5\n",
    "        column = i%5\n",
    "        \n",
    "        X_train, X_val = features_train.iloc[train_index], features_train.iloc[test_index]\n",
    "        y_train, y_val = labels_train.iloc[train_index], labels_train.iloc[test_index]\n",
    "        \n",
    "        model = model_obj\n",
    "        hist = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=n_epochs, batch_size=32,\n",
    "                        verbose=0)\n",
    "        \n",
    "        validation = model.evaluate(X_val, y_val)\n",
    "        validation_scores.append(validation)\n",
    "        ax = axes[row,col]\n",
    "        k = 'val_loss'\n",
    "        d = hist.history[k]\n",
    "        ax.plot(d, label=k, colors=colors[1])\n",
    "        ax.set_title(f'Fold {i+1} Validation')\n",
    "    plt.subplots_adjust(left=None, right=None, bottom=None, top=None, wspace=.5, hspace=None)\n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    \n",
    "    validation_score = np.mean(validation_scores)\n",
    "    print(f'Mean Validation Score: {validation_score}')\n",
    "    print(f'STD of Validation Scores: {np.std(validation_scores)}')\n",
    "    return validation_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Baseline Model\n",
    "\n",
    "Here, it is also important to define your evaluation metric that you will look to optimize while tuning the model.   \n",
    "\n",
    "In general, model training to optimize this metric may consist of using a validation and test set if data is plentiful, or k-folds cross-validation if data is limited. We set up a k-folds cross-validation for this task since the dataset is not overly large.  \n",
    "\n",
    "Build an initial sequential model with 2 hidden relu layers. The first should have 7 hidden units, and the second 10 hidden units. Finally, add a third layer with a linear activation function to output our predictions for the total loan payment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; define and compile an initial model as described\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "inputs = X_train.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(inputs, activation='relu'))\n",
    "model.add(Dense(7, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Baseline Model with K-Folds Cross Validation\n",
    "\n",
    "Use your k-folds function to evaluate the baseline model.  \n",
    "\n",
    "Note: This code block is likely to take 10-20 minutes to run depending on the specs on your computer.\n",
    "Because of time dependencies, it can be interesting to begin timing these operations for future reference.\n",
    "\n",
    "Here's a simple little recipe to achieve this:\n",
    "```\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "later = datetime.datetime.now()\n",
    "elapsed = later - now\n",
    "print('Time Elapsed:', elapsed)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Please provide as model inputs either a single array or a list of arrays. You passed: x=       loan_amnt home_ownership  funded_amnt_inv verification_status  \\\n28927     6000.0           RENT       5950.00000     Source Verified   \n18623     5000.0           RENT       4950.00000     Source Verified   \n30212    25000.0           RENT      23457.05000            Verified   \n33624    12000.0       MORTGAGE      12000.00000            Verified   \n21095    24000.0       MORTGAGE      23950.00000            Verified   \n23159    15000.0       MORTGAGE      13088.66441     Source Verified   \n8944     10000.0           RENT      10000.00000        Not Verified   \n16768    16225.0       MORTGAGE      16225.00000     Source Verified   \n35123     6000.0       MORTGAGE       5975.00000            Verified   \n8167      8000.0       MORTGAGE       8000.00000        Not Verified   \n25406     5000.0           RENT       5000.00000        Not Verified   \n36852    12000.0       MORTGAGE      11725.00000        Not Verified   \n8315     35000.0       MORTGAGE      26575.00000            Verified   \n8668     12000.0       MORTGAGE      12000.00000            Verified   \n30184    25000.0           RENT      16231.68103            Verified   \n2698      1000.0           RENT       1000.00000            Verified   \n29258    24000.0       MORTGAGE      14950.64088            Verified   \n37594    13000.0           RENT      12499.99959            Verified   \n21144     4200.0            OWN       4175.00000        Not Verified   \n9750      5000.0       MORTGAGE       5000.00000        Not Verified   \n22168    13000.0       MORTGAGE      12475.00000     Source Verified   \n29695    25000.0           RENT      15783.43465            Verified   \n36299     6200.0           RENT       6150.00000            Verified   \n30556    20400.0           RENT      20400.00000            Verified   \n35471     6000.0       MORTGAGE       5950.00000            Verified   \n23284    18000.0       MORTGAGE      17900.00000     Source Verified   \n15021     1800.0           RENT       1800.00000        Not Verified   \n28762     4800.0       MORTGAGE       4721.28235        Not Verified   \n31592     6525.0           RENT       6500.00000        Not Verified   \n11507    15000.0       MORTGAGE      14750.00000     Source Verified   \n...          ...            ...              ...                 ...   \n20355     5000.0            OWN       5000.00000        Not Verified   \n16972    11000.0           RENT      11000.00000        Not Verified   \n2338     12000.0           RENT      12000.00000        Not Verified   \n29534    13200.0       MORTGAGE      12520.83374        Not Verified   \n11894     5000.0           RENT       5000.00000            Verified   \n28513     4500.0           RENT       4500.00000        Not Verified   \n3252      6000.0           RENT       6000.00000            Verified   \n8028     14400.0       MORTGAGE      13400.00000        Not Verified   \n4195     21000.0           RENT      21000.00000            Verified   \n23728    10000.0       MORTGAGE       9950.00000     Source Verified   \n22461     9600.0       MORTGAGE       9525.00000        Not Verified   \n6648     30100.0       MORTGAGE      30100.00000            Verified   \n30255    24000.0           RENT      23673.01145            Verified   \n42535     2525.0           RENT        225.00000        Not Verified   \n6484     30000.0       MORTGAGE      29500.00000            Verified   \n26626     8400.0       MORTGAGE       8300.00000            Verified   \n7985     25000.0           RENT      19800.00000            Verified   \n17476     2500.0            OWN       2500.00000     Source Verified   \n31140     5000.0           RENT       5000.00000        Not Verified   \n3325      1500.0            OWN       1500.00000        Not Verified   \n17747    34000.0       MORTGAGE      33068.77746            Verified   \n36249     2800.0            OWN       2775.00000        Not Verified   \n33710     2500.0           RENT       2500.00000        Not Verified   \n5664     15000.0       MORTGAGE      15000.00000            Verified   \n23166     7000.0           RENT       6900.00000            Verified   \n23766    15600.0       MORTGAGE      12771.01835     Source Verified   \n7763     35000.0       MORTGAGE      27597.14945            Verified   \n15377    10000.0       MORTGAGE      10000.00000            Verified   \n17730     5425.0            OWN       5425.00000        Not Verified   \n15725     3150.0           RENT       3150.00000            Verified   \n\n      emp_length  installment  annual_inc  \n28927    5 years       195.73     50000.0  \n18623     1 year       160.47     65000.0  \n30212     1 year       839.16    103250.0  \n33624  10+ years       407.63     98004.0  \n21095    6 years       588.75     90000.0  \n23159  10+ years       460.01     74400.0  \n8944     7 years       315.63     24000.0  \n16768  10+ years       350.68     70800.0  \n35123    2 years       204.83     62000.0  \n8167         NaN       243.34     32000.0  \n25406     1 year       155.56     38250.0  \n36852    9 years       383.37     54000.0  \n8315     6 years       680.49    125000.0  \n8668   10+ years       404.27    150000.0  \n30184   < 1 year       843.63    106000.0  \n2698         NaN        34.50     11820.0  \n29258    6 years       373.28     88100.0  \n37594     1 year       441.00     51996.0  \n21144    6 years        89.99     44500.0  \n9750   10+ years       157.82     33000.0  \n22168    5 years       400.87     37200.0  \n29695    4 years       403.03     99996.0  \n36299    7 years       211.27     45000.0  \n30556    2 years       660.65     80004.0  \n35471    2 years       189.67     52000.0  \n23284    5 years       469.81     60000.0  \n15021  10+ years        39.58     27000.0  \n28762    2 years       146.88     52000.0  \n31592     1 year       229.64     38000.0  \n11507    9 years       391.51     75000.0  \n...          ...          ...         ...  \n20355  10+ years       155.05     60000.0  \n16972    8 years       341.11     44000.0  \n2338     4 years       373.33     32000.0  \n29534  10+ years       334.70     62400.0  \n11894    4 years       177.00    200000.0  \n28513    7 years       155.38     90750.0  \n3252     2 years       155.75     38400.0  \n8028     4 years       313.02     70000.0  \n4195      1 year       676.73     93000.0  \n23728    2 years       377.47    108000.0  \n22461  10+ years       289.54     75000.0  \n6648     6 years       787.79    100000.0  \n30255    2 years       818.50     60000.0  \n42535   < 1 year        80.69    110000.0  \n6484   10+ years       921.11     94000.0  \n26626    8 years       261.34     39700.0  \n7985     6 years       436.46    117000.0  \n17476    2 years        80.24     20004.0  \n31140    2 years       161.06     42000.0  \n3325     6 years        48.86     34056.0  \n17747    2 years       728.61    195000.0  \n36249    4 years        96.28     54000.0  \n33710    5 years        82.01     55000.0  \n5664     9 years       488.60     85000.0  \n23166    2 years       159.20     36188.0  \n23766  10+ years       273.76     80000.0  \n7763   10+ years       634.10     74004.0  \n15377        NaN       308.73     61000.0  \n17730    5 years       186.84    150000.0  \n15725    9 years       103.12     15300.0  \n\n[34455 rows x 7 columns]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-4b430ca9b779>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mk_folds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mlater\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0melapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlater\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-80edd6c2ff5a>\u001b[0m in \u001b[0;36mk_folds\u001b[0;34m(features_train, labels_train, model_obj, k, n_epochs)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_obj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         hist = model.fit(X_train, y_train, batch_size=32,\n\u001b[0;32m---> 21\u001b[0;31m                          epochs=n_epochs, verbose=0, validation_data = (X_val, y_val))\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;31m#Note: verboxe=0 turns off printouts regarding training for each epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m#Potential simpler methodology\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    951\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    662\u001b[0m                                      \u001b[0;34m'either a single '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m                                      \u001b[0;34m'array or a list of arrays. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m                                      'You passed: x=' + str(x))\n\u001b[0m\u001b[1;32m    665\u001b[0m                 \u001b[0mall_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Please provide as model inputs either a single array or a list of arrays. You passed: x=       loan_amnt home_ownership  funded_amnt_inv verification_status  \\\n28927     6000.0           RENT       5950.00000     Source Verified   \n18623     5000.0           RENT       4950.00000     Source Verified   \n30212    25000.0           RENT      23457.05000            Verified   \n33624    12000.0       MORTGAGE      12000.00000            Verified   \n21095    24000.0       MORTGAGE      23950.00000            Verified   \n23159    15000.0       MORTGAGE      13088.66441     Source Verified   \n8944     10000.0           RENT      10000.00000        Not Verified   \n16768    16225.0       MORTGAGE      16225.00000     Source Verified   \n35123     6000.0       MORTGAGE       5975.00000            Verified   \n8167      8000.0       MORTGAGE       8000.00000        Not Verified   \n25406     5000.0           RENT       5000.00000        Not Verified   \n36852    12000.0       MORTGAGE      11725.00000        Not Verified   \n8315     35000.0       MORTGAGE      26575.00000            Verified   \n8668     12000.0       MORTGAGE      12000.00000            Verified   \n30184    25000.0           RENT      16231.68103            Verified   \n2698      1000.0           RENT       1000.00000            Verified   \n29258    24000.0       MORTGAGE      14950.64088            Verified   \n37594    13000.0           RENT      12499.99959            Verified   \n21144     4200.0            OWN       4175.00000        Not Verified   \n9750      5000.0       MORTGAGE       5000.00000        Not Verified   \n22168    13000.0       MORTGAGE      12475.00000     Source Verified   \n29695    25000.0           RENT      15783.43465            Verified   \n36299     6200.0           RENT       6150.00000            Verified   \n30556    20400.0           RENT      20400.00000            Verified   \n35471     6000.0       MORTGAGE       5950.00000            Verified   \n23284    18000.0       MORTGAGE      17900.00000     Source Verified   \n15021     1800.0           RENT       1800.00000        Not Verified   \n28762     4800.0       MORTGAGE       4721.28235        Not Verified   \n31592     6525.0           RENT       6500.00000        Not Verified   \n11507    15000.0       MORTGAGE      14750.00000     Source Verified   \n...          ...            ...              ...                 ...   \n20355     5000.0            OWN       5000.00000        Not Verified   \n16972    11000.0           RENT      11000.00000        Not Verified   \n2338     12000.0           RENT      12000.00000        Not Verified   \n29534    13200.0       MORTGAGE      12520.83374        Not Verified   \n11894     5000.0           RENT       5000.00000            Verified   \n28513     4500.0           RENT       4500.00000        Not Verified   \n3252      6000.0           RENT       6000.00000            Verified   \n8028     14400.0       MORTGAGE      13400.00000        Not Verified   \n4195     21000.0           RENT      21000.00000            Verified   \n23728    10000.0       MORTGAGE       9950.00000     Source Verified   \n22461     9600.0       MORTGAGE       9525.00000        Not Verified   \n6648     30100.0       MORTGAGE      30100.00000            Verified   \n30255    24000.0           RENT      23673.01145            Verified   \n42535     2525.0           RENT        225.00000        Not Verified   \n6484     30000.0       MORTGAGE      29500.00000            Verified   \n26626     8400.0       MORTGAGE       8300.00000            Verified   \n7985     25000.0           RENT      19800.00000            Verified   \n17476     2500.0            OWN       2500.00000     Source Verified   \n31140     5000.0           RENT       5000.00000        Not Verified   \n3325      1500.0            OWN       1500.00000        Not Verified   \n17747    34000.0       MORTGAGE      33068.77746            Verified   \n36249     2800.0            OWN       2775.00000        Not Verified   \n33710     2500.0           RENT       2500.00000        Not Verified   \n5664     15000.0       MORTGAGE      15000.00000            Verified   \n23166     7000.0           RENT       6900.00000            Verified   \n23766    15600.0       MORTGAGE      12771.01835     Source Verified   \n7763     35000.0       MORTGAGE      27597.14945            Verified   \n15377    10000.0       MORTGAGE      10000.00000            Verified   \n17730     5425.0            OWN       5425.00000        Not Verified   \n15725     3150.0           RENT       3150.00000            Verified   \n\n      emp_length  installment  annual_inc  \n28927    5 years       195.73     50000.0  \n18623     1 year       160.47     65000.0  \n30212     1 year       839.16    103250.0  \n33624  10+ years       407.63     98004.0  \n21095    6 years       588.75     90000.0  \n23159  10+ years       460.01     74400.0  \n8944     7 years       315.63     24000.0  \n16768  10+ years       350.68     70800.0  \n35123    2 years       204.83     62000.0  \n8167         NaN       243.34     32000.0  \n25406     1 year       155.56     38250.0  \n36852    9 years       383.37     54000.0  \n8315     6 years       680.49    125000.0  \n8668   10+ years       404.27    150000.0  \n30184   < 1 year       843.63    106000.0  \n2698         NaN        34.50     11820.0  \n29258    6 years       373.28     88100.0  \n37594     1 year       441.00     51996.0  \n21144    6 years        89.99     44500.0  \n9750   10+ years       157.82     33000.0  \n22168    5 years       400.87     37200.0  \n29695    4 years       403.03     99996.0  \n36299    7 years       211.27     45000.0  \n30556    2 years       660.65     80004.0  \n35471    2 years       189.67     52000.0  \n23284    5 years       469.81     60000.0  \n15021  10+ years        39.58     27000.0  \n28762    2 years       146.88     52000.0  \n31592     1 year       229.64     38000.0  \n11507    9 years       391.51     75000.0  \n...          ...          ...         ...  \n20355  10+ years       155.05     60000.0  \n16972    8 years       341.11     44000.0  \n2338     4 years       373.33     32000.0  \n29534  10+ years       334.70     62400.0  \n11894    4 years       177.00    200000.0  \n28513    7 years       155.38     90750.0  \n3252     2 years       155.75     38400.0  \n8028     4 years       313.02     70000.0  \n4195      1 year       676.73     93000.0  \n23728    2 years       377.47    108000.0  \n22461  10+ years       289.54     75000.0  \n6648     6 years       787.79    100000.0  \n30255    2 years       818.50     60000.0  \n42535   < 1 year        80.69    110000.0  \n6484   10+ years       921.11     94000.0  \n26626    8 years       261.34     39700.0  \n7985     6 years       436.46    117000.0  \n17476    2 years        80.24     20004.0  \n31140    2 years       161.06     42000.0  \n3325     6 years        48.86     34056.0  \n17747    2 years       728.61    195000.0  \n36249    4 years        96.28     54000.0  \n33710    5 years        82.01     55000.0  \n5664     9 years       488.60     85000.0  \n23166    2 years       159.20     36188.0  \n23766  10+ years       273.76     80000.0  \n7763   10+ years       634.10     74004.0  \n15377        NaN       308.73     61000.0  \n17730    5 years       186.84    150000.0  \n15725    9 years       103.12     15300.0  \n\n[34455 rows x 7 columns]"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Your code here; use your k-folds function to evaluate the baseline model.\n",
    "import time\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "now = datetime.datetime.now()\n",
    "k_folds(X_train, y_train, model)\n",
    "later = datetime.datetime.now()\n",
    "elapsed = later-now\n",
    "print('Time Elapsed:', elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intentionally Overfitting a Model\n",
    "\n",
    "Now that you've developed a baseline model, its time to intentionally overfit a model. To overfit a model, you can:\n",
    "* Add layers\n",
    "* Make the layers bigger\n",
    "* Increase the number of training epochs\n",
    "\n",
    "Again, be careful here. Think about the limitations of your resources, both in terms of your computers specs and how much time and patience you have to let the process run. Also keep in mind that you will then be regularizing these overfit models, meaning another round of experiments and more time and resources.  \n",
    "\n",
    "For example, here are some timing notes on potential experiments run on a Macbook Pro 3.1 GHz Intel Core i5 with 16gb of RAM:\n",
    "\n",
    "* Using our 10 fold cross validation methodology, a 5-layer neural network with 10 units per hidden layer and 100 epochs took approximately 15 minutes to train and validate  \n",
    "\n",
    "* Using our 10 fold cross validation methodology, a 5-layer neural network with 25 units per hidden layer and 100 epochs took approximately 25 minutes to train and validate  \n",
    "\n",
    "* Using our 10 fold cross validation methodology, a 5-layer neural network with 10 units per hidden layer and 250 epochs took approximately 45 minutes to train and validate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; try some methods to overfit your network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; try some methods to overfit your network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; try some methods to overfit your network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularizing the Model to Achieve Balance  \n",
    "\n",
    "Now that you have a powerful model (albeit an overfit one), we can now increase the generalization of the model by using some of the regularization techniques we discussed. Some options you have to try include:  \n",
    "* Adding dropout\n",
    "* Adding L1/L2 regularization\n",
    "* Altering the layer architecture (add or remove layers similar to above)  \n",
    "\n",
    "This process will be constrained by time and resources. Be sure to test at least 2 different methodologies, such as dropout and L2 regularization. If you have the time, feel free to continue experimenting.\n",
    "\n",
    "Notes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; try some regularization or other methods to tune your network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; try some regularization or other methods to tune your network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; try some regularization or other methods to tune your network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; try some regularization or other methods to tune your network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Evaluation\n",
    "\n",
    "Now that you have selected a network architecture, tested various regularization procedures and tuned hyperparameters via a validation methodology, it is time to evaluate your finalized model once and for all. Fit the model using all of the training and validation data using the architecture and hyperparameters that were most effective in your expirements above. Afterwards, measure the overall performance on the hold-out test data which has been left untouched (and hasn't leaked any data into the modelling process)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; final model training on entire training set followed by evaluation on hold-out data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/\n",
    "\n",
    "https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n",
    "\n",
    "https://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/\n",
    "\n",
    "https://stackoverflow.com/questions/37232782/nan-loss-when-training-regression-network\n",
    "https://www.springboard.com/blog/free-public-data-sets-data-science-project/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, we investigated some data from *The Lending Club* in a complete data science pipeline regarding neural networks. We began with reserving a hold-out set for testing which never was touched during the modeling phase. From there, we implemented a k-fold cross validation methodology in order to assess an initial baseline model and various regularization methods. From here, we'll begin to investigate other neural network architectures such as CNNs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
